---
title: "3-plots.Rmd"
output: html_document
---
# Main steps:
# Plot shared iSNVs
# Summarize shared iSNVs in table form
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
remove(list=ls())
# Source config file
library(here)
here()
source(here('scripts/config.R'))
library(ggbeeswarm)
library(ggsci)
#library(gtsummary)
library(colorspace)
library(cowplot)
library(ggridges)
library(infer)
library(yardstick)
library(ggpubr)
library(rstatix)
library(ape)
library(ggtree)
library(harrietr)
library(ggh4x)
library(tidyverse)
library(phytools)
#save.image(file = here('hh.RData'))
load(here('hh.RData'))

# Read in run summaries
vitoria_run_summary = read_tsv("/uufs/chpc.utah.edu/common/home/walter-group2/tb/mtb-call2/results/vitoria_run_summary_2023-12-23_17-17-22.350335.tsv")
bc_run_summary = read_tsv("/uufs/chpc.utah.edu/common/home/walter-group2/tb/mtb-call2/results/bc_hh_members_run_summary_2023-12-21_15-51-57.471676.tsv")
walker_run_summary = read_tsv("/uufs/chpc.utah.edu/common/home/walter-group2/tb/mtb-call2/results/pipeline_run_summary_2023-07-07_01-28-31.690645.tsv")

run_summary = bind_rows(vitoria_run_summary,bc_run_summary,walker_run_summary) %>%
  mutate(mixed = case_when(str_detect(Strain, ';') ~ 'mixed', 
                           TRUE ~ 'single'))
run_summary %>%
  filter(mixed == 'mixed')

run_summary %>%
  select(Batch, Strain) %>%
  filter(Batch == 'walker') %>%
  pull(Strain) %>% table()
```

```{r lineages pie}
lineages = walker_run_summary %>% mutate(strain = str_extract(Strain, '[a-z0-9]+')) %>%
  filter(!strain == 'a1' & !is.na(strain)) %>% pull(strain) %>% unique()
lineages
pie1 = vitoria_run_summary %>%
  mutate(lineage = str_extract(Strain, '[a-z0-9]+'), 
         Strain = str_remove(Strain, 'lineage')) %>%
  filter(!lineage == 'a1') %>%
  group_by(lineage, Strain) %>%
  summarize(n = n()) %>%
  ggplot(aes(x = "", y = n, fill = lineage)) +
  geom_col(color = "black") + 
  geom_text(aes(label = Strain),
            position = position_stack(vjust = 0.5)) +
  coord_polar(theta = "y") +
  scale_fill_npg(name = 'Lineage', limits = lineages) + theme_void()
pie1
pie2= bc_run_summary %>%
  mutate(lineage = str_extract(Strain, '[a-z0-9]+'),
                  Strain = str_remove(Strain, 'lineage')) %>%
  filter(!lineage == 'a1') %>%
  group_by(lineage, Strain) %>%
  summarize(n = n()) %>%
  ggplot(aes(x = "", y = n, fill = lineage)) +
  geom_col(color = "black") +
  geom_text(aes(label = Strain),
            position = position_stack(vjust = 0.5)) +
  coord_polar(theta = "y") +
  scale_fill_npg(name = 'Lineage', limits = lineages) + theme_void()

  
pie3 = walker_run_summary %>%
  mutate(lineage = str_extract(Strain, '[a-z0-9]+')) %>%
  filter(!lineage == 'a1') %>%
  group_by(lineage, Strain) %>%
  summarize(n = n()) %>%
  ggplot(aes(x = "", y = n, fill = lineage, color = 'grey')) +
  geom_col(color = "black") +
  coord_polar(theta = "y") +
  scale_fill_npg(name = 'Lineage', limits = lineages) + theme_void()

pies = plot_grid(pie1 + theme(legend.position="none") + theme( plot.margin = unit(c(-.5, -.5, -.5, -.5),"cm")),
                 pie2 + theme(legend.position="none") + theme( plot.margin = unit(c(-.5, -.5, -.5, -.5),"cm")),
                 pie3 + theme(legend.position="none") + theme( plot.margin = unit(c(-.5, -.5, -.5, -.5),"cm")),
                 labels = 'auto', vjust = 8, nrow = 1, label_size = 12)
pies
legend = get_legend(
  pie3 + theme(legend.box.margin = margin(0, 0, 0, 12))
)

# Add legend back
pies_legend = plot_grid(pies, legend, rel_widths = c(3, .5))
pies_legend
ggsave(plot = pies_legend, filename = here('plots/lineage_pies.pdf'))

```
```{r pairwise diffs}
#### pairwise snp differences ####

# Read in fastas, get pairwise distances
fasta_file1 <- here('results/fasta/vitoria_PPEmask_snps.fa')
f1 <- read.dna(file = fasta_file1, format = 'fasta')
d1 <- dist.dna(f1, model = 'N', as.matrix = TRUE, pairwise.deletion = TRUE)  

meta_vitoria_file = here('metadata/vitoria.csv')
meta_vitoria = read_csv(meta_vitoria_file)

# Distances 
d_long1 <- d1 %>% 
  melt_dist() %>% 
  rowwise() %>%
  mutate(pair_name = paste(sort(c(iso1,iso2)), collapse = '_')) %>%
  # Remove duplicates--already done
  group_by(pair_name) %>% slice(1) %>%
  left_join(meta_vitoria[,c("Index case","HHC","months","pair_name")], by = c('pair_name')) %>%
  mutate(pair_id = case_when(iso1 == iso2 ~ 'Sample',
                             !is.na(months) ~ 'Household',
                             TRUE ~ 'Outside household'))

table(d_long1$pair_id)

# Read in fastas, get pairwise distances
fasta_file2 <- here('results/fasta/bc_PPEmask_snps.fa')
f2 <- read.dna(file = fasta_file2, format = 'fasta')
d2 <- dist.dna(f2, model = 'N', as.matrix = TRUE, pairwise.deletion = FALSE)  

meta_bc_file = here('metadata/bc.csv')
meta_bc = read_csv(meta_bc_file)
meta_bc
# Distances 
d_long2 <- d2 %>% 
  melt_dist() %>% 
  rowwise() %>%
  mutate(pair_name = paste(sort(c(iso1,iso2)), collapse = '_')) %>%
  # Remove duplicates--already done
  group_by(pair_name) %>% slice(1) %>%
  left_join(meta_bc[,c('Run','library','hh')], by = c('iso1' = 'Run')) %>%
  left_join(meta_bc[,c('Run','library','hh')], by = c('iso2' = 'Run')) %>%
  dplyr::rename(sample_name.x = library.x, sample_name.y= library.y,house.x = hh.x, house.y = hh.y) %>%
  mutate(pair_id = case_when(sample_name.x == sample_name.y ~ 'Sample',
                             house.x == house.y ~ 'Household',
                             TRUE ~ 'Outside household'))
table(d_long2$pair_id) 

# 'BC06-Mtb290', 'BC06-Mtb296' missing from sequence data. 

# Histogram of pairwise SNP distances--include all. 
d_long2 %>% 
  ggplot(aes(x = dist, fill = pair_id)) + 
  geom_histogram() +
  facet_grid(~pair_id, scales = 'free') + 
  theme_classic() + 
  scale_fill_npg(name = 'Comparison type') + 
  xlab('Pairwise SNP distance')

# Read in fastas, get pairwise distances
fasta_file4 <- here('results/fasta/walker_PPEmask_snps.fa')
f4 <- read.dna(file = fasta_file4, format = 'fasta')
d4 <- dist.dna(f4, model = 'N', as.matrix = TRUE, pairwise.deletion = TRUE)  

meta_walker_file = here('metadata/walker.csv')
meta_walker = read_csv(meta_walker_file)

# Distances 
d_long4 <- d4 %>% 
  melt_dist() %>% 
  rowwise() %>%
  mutate(pair_name = paste(sort(c(iso1,iso2)), collapse = '_')) %>%
  # Remove duplicates--already done
  group_by(pair_name) %>% slice(1) %>%
  left_join(meta_walker %>% 
              dplyr::select(pair_name, epi_link,epi_connection), by = 'pair_name') %>%
  dplyr::mutate(pair_id = case_when(iso1 == iso2 ~ 'Sample',
                                    #epi_connection == 'Household / family' ~ 'Household or Linked',
                                    epi_link == 'Yes' ~ 'Linked',     
                                    TRUE ~ 'Unlinked'))

table(d_long4$pair_id)

# Combine into a single plot
d_all = bind_rows(d_long1 %>% mutate(study = 'Colangeli et al. (2020)'), 
                  d_long2 %>% mutate(study = 'Guthrie et al. (2018)'),
                  d_long4 %>% mutate(study = 'Walker et al. (2014)')) %>% 
   mutate(pair_id = case_when(pair_id == 'Linked' ~ 'Household',
                             pair_id == 'Outside household' ~ 'Unlinked', 
                             TRUE ~ pair_id))

# Plot all together: need to use facet_wrap to free the y-axis. 
p_dists = ggplot(d_all, aes(x = dist, fill = pair_id, )) + 
  geom_histogram() +
  facet_wrap(vars(study, pair_id), scales = 'free', nrow = 3) + 
  theme_classic() + 
  scale_fill_npg(name = 'Comparison type') + 
  xlab('Pairwise SNP distance') 

# update scales so that each row shares an x-axis. (Need to first set scales as free, then define limits.)
p_dists = p_dists + 
  facetted_pos_scales(
    x = list(
      pair_id == "Household" ~ scale_x_continuous(limits = c(0,22), breaks = c(0,5,10,15,20), labels = c(0,5,10,15,20)),
      pair_id == "Unlinked" ~ scale_x_continuous(limits = c(0,2000), breaks = c(0,500,1000,1500,2000), labels = c(0,500,1000,1500,2000))
    )
  )


# Look at proportion of epidemiologically linked pairs that don't fall under threshold. 
d_all %>%
  #group_by(study) %>%
  ungroup() %>%
  filter(pair_id == 'Household') %>%
  mutate(meets_threshold5 = case_when(dist <= 5 ~ TRUE, TRUE ~ FALSE), 
         meets_threshold12 = case_when(dist <= 12 ~ TRUE, TRUE ~ FALSE)) %>%
  summarize(n() - sum(meets_threshold5), n(), 1-sum(meets_threshold5)/n(), n() - sum(meets_threshold12), 1-sum(meets_threshold12)/n(), n())

```
```{r clusters}
# Cluster isolates from each study to see if clusters are larger than 2
# Vitoria- none larger than 2
clust1 = hclust(as.dist(d1), method = 'complete', members = NULL)
memberships1 = cutree(clust1, h = 12) 
table(memberships1)

# Guthrie - cluster 10 larger than 2
clust2 = hclust(as.dist(d2), method = 'complete', members = NULL)
memberships2 = cutree(clust2, h = 12) 
table(memberships2) > 2

# Walker - a few clusters larger than 2
clust4 = hclust(as.dist(d4), method = 'complete', members = NULL)
memberships4 = cutree(clust4, h = 12) 
sort(table(memberships4))

# All clusters
clusters = enframe(c(memberships1, memberships2, memberships4), name = 'Sample', value = 'Cluster')

# Add cluster memberships to full pairwise distances table
d_full = d_all %>%
  dplyr::left_join(clusters, by = join_by(iso1 == Sample)) %>%
  left_join(clusters, by = join_by(iso2 == Sample)) %>%
  rename(Cluster1 = Cluster.x, Cluster2 = Cluster.y) %>%
  mutate(cluster_status = case_when(Cluster1 == Cluster2 ~ 'Clustered',
                   Cluster1 != Cluster2 ~ 'Not clustered',
                   TRUE ~ NA))

table(d_full$pair_id, d_full$cluster_status)
```
```{r iqtree}
#### Plot IQTrees ####
tre1 = read.tree(here('results/tree/vitoria_GTR.treefile'))
tre2 = read.tree(here('results/tree/bc_GTR.treefile'))
tre3 = read.tree(here('results/tree/walker_GTR.treefile'))

# Re-arrange meta_vitoria to per-sample
meta_vitoria_tre = meta_vitoria %>%
  mutate(hh=row_number()) %>%
  select(Run.x,Run.y, hh) %>%
  pivot_longer(cols = c(Run.x,Run.y)) %>%
  select(-name) %>%
  relocate(value)

# Mid-point root tree, all in same lineage. 
tre1 = midpoint_root(tre1)

p1 = ggtree(tre1) %<+%
  meta_vitoria_tre +
  geom_tippoint(aes(color = as.factor(hh)), size = 2) +
  theme(legend.position = "none") +
  scale_color_manual(values = rainbow_hcl(25)) +
  geom_treescale(x = .0004, y = -.5,  family = 'arial')

# Re-arrange meta_bc to per-sample
meta_bc_tre <- meta_bc %>% 
  relocate(Run)

# Root on lineage1.2.1.2.1 isolates. 
#lin1_isolates = bc_run_summary %>% filter(Strain == 'lineage1.2.1.2.1') %>% pull(Sample)
#tre2_rooted = root(tre2, outgroup = lin1_isolates)

# Mid-point root tree
tre2_rooted = midpoint_root(tre2)

p2 = ggtree(tre2_rooted) %<+%
  meta_bc_tre +
  geom_tippoint(aes(color = as.factor(hh))) +
  theme(legend.position = "none") +
  scale_color_manual(values = rainbow_hcl(12)) + 
  geom_treescale( family = 'arial')
p2

# Re-arrange meta_walker to per-sample
meta_walker_tre <- meta_walker %>% 
  mutate(epi_link = case_when(epi_link == 'Yes' ~ row_number(), 
                        TRUE ~ NA)) %>% 
  select(run_accession.x, run_accession.y,epi_link) %>%
  pivot_longer(cols = c(run_accession.x,run_accession.y)) %>%
  relocate(value) %>%
  select(-name)

# Mid-point root tree
tre3_rooted = midpoint_root(tre3)

# Access tree data
tre3_dat = tre3_rooted %>% as.treedata %>% as_tibble
hh_members = meta_walker_tre %>% filter(!is.na(epi_link)) %>% pull(value)
hh_members

p3 = ggtree(tre3_rooted) %<+%
  meta_walker_tre +
  geom_tippoint(aes(color = as.factor(epi_link))) +
  theme(legend.position = "none") +
  scale_color_manual(values = rainbow_hcl(11), na.translate = FALSE) + 
  geom_treescale(x = .001, y = -10, family = 'arial')

# Get MRCA nodes to highlight with asterix: 
getMRCA(tre3_rooted, c('ERR400343','ERR400334')) #359
getMRCA(tre3_rooted, c('ERR400385','ERR400384')) #361
getMRCA(tre3_rooted, c('ERR400511','ERR400513')) #304
getMRCA(tre3_rooted, c('ERR400476','ERR400383')) #403
getMRCA(tre3_rooted, c('ERR400498','ERR400522')) #299
getMRCA(tre3_rooted, c('ERR400306','ERR400322')) #378
getMRCA(tre3_rooted, c('ERR400306','ERR400369')) #378
getMRCA(tre3_rooted, c('ERR400527','ERR400318')) #317
getMRCA(tre3_rooted, c('ERR400318','ERR400536')) #318
getMRCA(tre3_rooted, c('ERR400364','ERR400462')) #285
getMRCA(tre3_rooted, c('ERR400420','ERR400518')) #315

# Highlight nodes for hh pairs
p3 = p3 + 
  geom_cladelab(node = c(359,361, 304, 403, 299, 378, 317, 318, 285, 315), 
                label = '*', barsize=0, vjust = .8, fontsize = 7, alpha = .9, hjust = 'center', vjust = 'center', 
                  family = 'arial') 
  
p_tre = plot_grid(plot_grid(p1,p2, nrow = 2, labels = c('Colangeli et al. (2020)', 'Guthrie et al. (2018'), label_size = 10), 
                  p3, ncol = 2, labels = c(NA, 'Walker et al. (2014)'), label_size = 10)

# Combine trees and snp distances. 
p_dists_tre = plot_grid(p_dists, p_tre, nrow = 1, labels = 'auto') 

p_dists_tre
#ggsave(p_tre, filename = here('plots/p_dist_tre.pdf'), width = 12, height = 8)
#ggsave(p_dists_tre, filename = here('plots/p_dist_tre.eps'), width = 12, height = 8) # need to use arial as treescale font

```
```{r shared iSNV summaries}

# Read in shared iSNV summaries
shared_snps_summary_vitoria = read_csv(here('results/processed/shared_snps_summary_vitoria.csv')) %>%
  mutate(study = 'Colangeli')
shared_snps_summary_bc= read_csv(here('results/processed/shared_snps_summary_bc.csv')) %>%
  mutate(study = 'Guthrie')
shared_snps_summary_walker = read_csv(here('results/processed/shared_snps_summary_walker.csv')) %>%
  mutate(study = 'Walker')

shared_snps_summary = bind_rows(shared_snps_summary_vitoria, shared_snps_summary_bc, shared_snps_summary_walker)

# Filter shared snps to those with expected depth, outside PPE genes
shared_snps_filtered = shared_snps_summary %>%
  filter(dp_flag == "Expected" & ppe_flag == 'Outside') %>%
  mutate(pair_id = case_when(pair_id == 'Linked' ~ 'Household',
                             pair_id == 'Outside household' ~ 'Unlinked', 
                             TRUE ~ pair_id), 
         ppe_flag = case_when(ppe_flag == 'Outside' ~ 'Outside PE/PPE genes', 
                              TRUE ~ ppe_flag)) %>%
  mutate(pair_id = factor(pair_id, levels = c('Sample','Household','Linked','Outside household','Unlinked'))) %>%
  mutate(study = case_when(study == 'Colangeli' ~ 'Colangeli et al. (2020)', 
                           study == 'Guthrie' ~ 'Guthrie et al. (2018)',
                           study == 'Walker' ~ 'Walker et al. (2014)', 
                          TRUE ~ NA))
 
```
```{r shared iSNV boxplot}
# Plot shared variants
p1 = shared_snps_filtered %>% 
  filter(threshold == .01) %>% ungroup() %>%
  mutate(n = n+1) %>%
  ggboxplot(x = 'study', y = 'n', color = 'pair_id', palette = 'jco', 
              add = "jitter") + 
   theme_classic() +
   scale_y_continuous(trans='log10') +
   theme(axis.text.x = element_text(angle = 45, vjust = .6)) + 
   ylab('Minority variants') + 
   scale_color_jco(name ="Comparison type") 
p1

# ggsave(p1, filename = here('plots/shared_isnvs_logscale.eps'),
#       bg = 'transparent', height = 6, width = 8)

# Supplement: Apply a more conservative minor allele frequency threshold
p2 = shared_snps_filtered %>% 
  filter(threshold %in% c(.01,.05,.1)) %>%
   ggboxplot(x = 'threshold', y = 'n', color = 'pair_id', palette = 'jco') + 
   facet_wrap(~study, scales = 'free_x') + #scales = 'free_x'
   theme_classic() +
   scale_y_continuous(trans='log10') +
   theme(axis.text.x = element_text(angle = 45, vjust = .6)) + 
   ylab('Minority variants') + 
   scale_color_jco(name ="Comparison type")

p2

ggsave(p2, filename = here('plots/shared_isnvs_logscale_mafs.pdf'),
     bg = 'transparent', height = 6, width = 8)

```
```{r shared iSNV table}
# Summarize into table
tab = shared_snps_filtered %>% 
  group_by(study,pair_id) %>% 
  rename('Comparison type' = pair_id) %>%
  filter(threshold == .01) %>%
  summarise(ci = list(mean_cl_normal(n) %>% 
                        rename(mean=y, lwr=ymin, upr=ymax))) %>% 
  unnest %>%
  mutate_if(is.numeric, round, 1)

tab %>%
  write_excel_csv(file = here('plots/table2.csv'))

tab

# Percentage in PE/PPE genes
shared_snps_summary %>% 
  group_by(study,ppe_flag, pair_id) %>% 
  mutate(pair_id = factor(pair_id, levels = c('Sample','Household','Linked','Sublineage','Outside household','Unlinked','Outside sublineage'))) %>%
  rename('Comparison type' = pair_id) %>%
  filter(threshold == .01 & dp_flag == 'Expected' & `Comparison type` == 'Sample') %>%
  ungroup() %>% group_by(study,ppe_flag) %>% 
  summarize(n = mean(n)) %>%
  mutate(total = sum(n), 
         freq = n / total) %>%
  mutate_if(is.numeric, round, 2)

# Statistical test for variation in mean iSNVs in household pairs outside of PPE versus random pairs, grouped by study
sample_snps_filt = shared_snps_filtered %>% 
  group_by(study,pair_id) %>% 
  filter(threshold == .01 & dp_flag == 'Expected' & pair_id != 'Sample') 

compare_means(data = sample_snps_filt, formula = n ~ pair_id, method = 'wilcox.test', group.by = 'study') # significant for all three studies

# Statistical test for variation in mean iSNVs per-sample across studies
sample_snps_filt = shared_snps_summary %>% 
  group_by(study,ppe_flag, pair_id) %>% 
  mutate(pair_id = factor(pair_id, levels = c('Sample','Household','Linked','Sublineage','Outside household','Unlinked','Outside sublineage'))) %>%
  filter(threshold == .01 & dp_flag == 'Expected' & ppe_flag == 'Outside' & pair_id == 'Sample') 

compare_means(data = sample_snps_filt, n ~ study, method = 'wilcox.test') # higher levels of variaiton in Colangelli compared to Guthrie or Walker.

```

```{r rocr}

# Combine iSNV data with consensus seq distances
d_all_full = shared_snps_summary %>% 
  filter(pair_id != 'Sample' & dp_flag == 'Expected' & ppe_flag == 'Outside') %>%
  ungroup() %>% group_by(study, threshold) %>% 
  mutate(pair_id = case_when(pair_id == 'Linked' ~ 'Household',
                             pair_id == 'Outside household' ~ 'Unlinked', 
                             TRUE ~ pair_id),
         hh = case_when(pair_id == 'Household' ~ 1, 
                        pair_id == 'Unlinked' ~ 0, TRUE ~ NA),
         hh = factor(hh), 
         threshold = as.factor(threshold)) %>%
  rename(n_isnvs = 'n') %>% 
  # Join with genetic distances between samples
  left_join(d_full, by = 'pair_name') %>% 
  ungroup()


# Add cluster status
d_all_full = d_all_full %>%
  mutate(clust12 = case_when(dist <= 12 ~ 'clustered',
                             dist > 12 ~ 'unclustered'), 
         clust12 = factor(clust12, levels = c('unclustered', 'clustered'), ordered = TRUE), # Set unclustered as reference level
         clust5 = case_when(dist <= 5 ~ 'clustered',
                             dist > 5 ~ 'unclustered'), 
         clust5 = factor(clust5, levels = c('unclustered', 'clustered'), ordered = TRUE)) %>%
  rename(study = study.x, pair_id = pair_id.x) %>% select(!c(study.y, pair_id.y)) %>%
  ungroup() %>% group_by(study) %>%
  # Get the z-score for iSNVs, by study
  mutate(n_isnvs_scaled = scale(n_isnvs), 
         dist_scale = scale(dist)) %>%
    mutate(study = case_when(study == 'Colangeli' ~ 'Colangeli et al. (2020)', 
                           study == 'Guthrie' ~ 'Guthrie et al. (2018)',
                           study == 'Walker' ~ 'Walker et al. (2014)', 
                          TRUE ~ NA))

table(d_all_full$study, useNA = 'always')
```
```{r models}
# Model 0: logistic regression for household membership as a function of cluster status, study, scaled shared iSNVs
m0 = glm(data = d_all_full[which(d_all_full$threshold == .01),], formula = hh ~ clust12 + study + n_isnvs_scaled, family = "binomial")
summary(m0)
cbind(exp(coefficients(m0)),exp(confint(m0))) %>%
  round(2)

# Model 0 predictions
m0_pred <- cbind(d_all_full[c('n_isnvs_scaled','study', 'hh', 'clust12')], predict(m0, newdata = d_all_full[c('clust12','n_isnvs_scaled','study')],type = "response", se = TRUE))

# Try for 5 SNP threshold
m1 = glm(data = d_all_full[which(d_all_full$threshold == .01),], formula = hh ~ clust5 + study + n_isnvs_scaled, family = "binomial")
summary(m1)
cbind(exp(coefficients(m1)),exp(confint(m1))) %>%
  round(2)

# Model 1 predictions
m1_pred <- cbind(d_all_full[c('n_isnvs','study', 'hh', 'clust5')], predict(m1, newdata = d_all_full[c('clust5','n_isnvs_scaled','study')],type = "response", se = TRUE))

# Model 2: consensus-based clustering only 
m2 = glm(data = d_all_full[which(d_all_full$threshold == .01),], formula = hh ~ clust12 + study, family = "binomial")
summary(m2)

# Model 2 predictions
m2_pred <- cbind(d_all_full[c('n_isnvs','study', 'hh', 'clust12')], predict(m2, newdata = d_all_full[c('clust12','n_isnvs_scaled','study')],type = "response", se = TRUE))

# Model 3 predictions
m3 = glm(data = d_all_full[which(d_all_full$threshold == .01),], formula = hh ~ n_isnvs_scaled + study, family = "binomial")
summary(m3)

# Model 3 predictions
m3_pred <- cbind(d_all_full[c('n_isnvs','study', 'hh', 'clust12')], predict(m3, newdata = d_all_full[c('clust12','n_isnvs_scaled','study')],type = "response", se = TRUE))

# AUCs
roc_auc(m0_pred, truth = hh, fit, event_level = 'second')
roc_auc(m1_pred, truth = hh, fit, event_level = 'second') # 5-SNP threshold performs similarly to the 12-SNP threshold.
roc_auc(m2_pred, truth = hh, fit, event_level = 'second') # without the minority variants
roc_auc(m3_pred, truth = hh, fit, event_level = 'second') # minority variants only

# Compare models with AUC curves.
p_roc = m0_pred %>% 
  mutate(model = 'Full model') %>%
  bind_rows(m2_pred %>% mutate(model = 'Genomic\nclustering')) %>%
  bind_rows(m3_pred %>% mutate(model = 'Minority\nvariants')) %>%
  mutate(model = factor(model, levels = c('Full model', 'Genomic\nclustering', 'Minority\nvariants'), ordered = TRUE)) %>%
  group_by(study,model) %>%
  roc_curve(truth = hh, fit, event_level = 'second') %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity, group = model, color = model)) + 
  geom_line() +
  theme_bw() +
  facet_wrap(vars(study)) +
  geom_abline(slope=1, intercept = 0, linetype="dotted") +
  scale_color_viridis_d(name = 'Model')

# Need to expand logistic regression to tidyr approach and use tidyr approach to generate predictions 
preds = d_all_full %>%
  nest(data = -threshold) %>%
  mutate(model = purrr::map(data, ~ glm(formula = hh ~ clust12 + study + n_isnvs_scaled, family = "binomial", data = .x)),
        fitted = purrr::map(model, augment)) %>%
  unnest(fitted)
preds

# Plot AUC with thresholds
p_roc_alt = preds %>%
  group_by(study, threshold) %>%
  roc_curve(truth = hh, .fitted, event_level = 'second') %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity, group = threshold, color = threshold)) + 
  geom_line() +
  theme_bw() +
  facet_wrap(vars(study)) +
  geom_abline(slope=1, intercept = 0, linetype="dotted") +
  scale_color_viridis_d(name = 'MAF threshold')
p_roc_alt

# Save
#ggsave(p_roc_alt, width = 8, height = 3, filename = here(paste0(plot_dir, 'roc_alternate_thresholds.pdf')))

# Print AUCs
preds %>%
  group_by(study, threshold) %>%
  roc_auc(truth = hh, .fitted, event_level = 'second') %>%
  # Get the threshold that maximizes AUC
  group_by(study) %>%
  arrange(study, -.estimate)
```
```{r genomic distance versus shared iSNVs}
# Compare pair-wise distance with number of shared iSNVs
p_dist_isnvs = d_all_full %>% 
  ggscatter(y = 'n_isnvs', x = 'dist', color = 'study',palette = 'jco') + 
            #facet.by = c('pair_id','study'), scales = 'free_x' ) +
  facet_grid(cols = vars(pair_id), rows = vars(study), scales = 'free') + 
  stat_cor(method = "pearson", size = 3, cor.coef.name = 'r') + 
  theme_classic() +
  ylab('Number shared minority variants') + xlab('Distance between consensus sequences') 
p_dist_isnvs

```

```{r maf}
#### Plot MAF across all samples ####
snps_vitoria = read_csv(here('results/processed/vitoria_snps.csv')) %>%
mutate(study = 'Colangeli')
snps_vitoria_sample = snps_vitoria %>%
filter(Sample %in% unique(snps_vitoria$Sample)[1:10])
snps_bc = read_csv(here('results/processed/bc_snps.csv')) %>%
mutate(study = 'Guthrie')
snps_bc_sample = snps_bc %>%
filter(Sample %in% unique(snps_bc$Sample)[1:10])

snps_walker = read_csv(here('results/processed/walker_snps.csv')) %>%
mutate(study = 'Walker')
snps_walker_sample = snps_walker %>%
filter(Sample %in% unique(snps_walker$Sample)[1:10])

# Include the first 5 samples that appear in the data.
snps_hh = bind_rows(snps_vitoria_sample,snps_bc_sample,snps_walker_sample) %>%
mutate(study = factor(study, levels = c('Colangeli','Guthrie','Walker')),
ppe_flag = case_when(ppe_flag == 'Outside' ~ 'Outside PE/PPE genes',
TRUE ~ ppe_flag)) %>%
  filter(!dp_flag == 'Low depth')  %>%
  mutate(study = case_when(study == 'Colangeli' ~ 'Colangeli et al. (2020)', 
                           study == 'Guthrie' ~ 'Guthrie et al. (2018)',
                           study == 'Walker' ~ 'Walker et al. (2014)', 
                          TRUE ~ NA))


p0 = snps_hh %>%
ggplot(aes(y = Sample, x = maf, fill = study)) +
#geom_density_ridges2(rel_min_height = 0.01) +
  geom_histogram()+
#geom_density_ridges(stat = 'binline', scale = 0.95, draw_baseline = TRUE, ) +
theme_classic() + 
  theme(axis.text.y=element_blank()) +
xlab('Minor allele frequency') +
ylab('Count of minority variants') +
facet_wrap(~ppe_flag) +
scale_fill_aaas() +
coord_cartesian(xlim = c(0,.5)) 

p0
ggsave(p0, filename = here('plots/maf.eps'), height = 6, width = 6.5, bg = 'transparent')
  
```

```{r stacked bar}
#### Shared iSNVs stacked barplot ####
# Stacked barplot
p_stacked_bar <- shared_snps_summary %>% 
  mutate(study = case_when(study == 'Colangeli' ~ 'Colangeli et al. (2020)', 
                           study == 'Guthrie' ~ 'Guthrie et al. (2018)',
                           study == 'Walker' ~ 'Walker et al. (2014)', 
                          TRUE ~ NA)) %>%
  filter(threshold == .01 & ppe_flag == 'Outside' & dp_flag == 'Expected') %>%
  mutate(pair_id = case_when(pair_id == 'Linked' ~ 'Household',
                             pair_id == 'Outside household' ~ 'Unlinked', 
                             TRUE ~ pair_id)) %>%
  arrange(-n) %>%
  mutate(shared = case_when(
    n >= 10 ~ '10+',
    n >= 5 & n <= 9~ '5-9',    
    n >= 2 & n <= 4~ '2-4',
    n == 1 ~ '1',
    n == 0 ~ '0'), 
    shared = factor(shared, levels = c('0','1','2-4','5-9','10+')),
    pair_id = factor(pair_id, levels = c('Sample','Household','Unlinked'))) %>% 
  select(pair_id, shared, study) %>% 
  group_by(pair_id, shared, study) %>%
  dplyr::summarize(n = n()) %>%
  ggplot(aes(x = pair_id,y = n,fill = shared)) +
  geom_bar(position = "fill", stat = "identity") + 
  facet_wrap(~study) + 
  scale_fill_viridis_d(name = 'Minority variants') + theme_classic() + xlab('Comparison type') + ylab('Proportion pairwise comparisons') + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) + 
  theme(plot.margin = unit(c(0,0,0,0), "lines")) + 
  theme(
    panel.background = element_rect(fill='transparent'), #transparent panel bg
    plot.background = element_rect(fill='transparent', color=NA), #transparent plot bg
    panel.grid.major = element_blank(), #remove major gridlines
    panel.grid.minor = element_blank(), #remove minor gridlines
    legend.background = element_rect(fill='transparent', color = NA), #transparent legend bg
    legend.box.background = element_rect(fill='transparent', color = NA), #transparent legend panel
    strip.background = element_rect(fill='transparent') 
  )

# Combine stacked barplot and ROC curve
p_roc_leg = get_legend(p_roc)
p_roc_noleg = p_roc + theme(legend.position="none")
p_stacked_bar_leg = get_legend(p_stacked_bar)
p_stacked_bar_noleg = p_stacked_bar + theme(legend.position="none")

# Combine
p_roc_bar = plot_grid(p_stacked_bar_noleg, p_stacked_bar_leg, p_roc_noleg, p_roc_leg, labels = c('a', NA, 'b', NA), 
                      nrow = 2, rel_widths = c(1.5, .3), scale = .9,
          label_size = 12)

ggsave(p_roc_bar, filename = here('plots/roc_stacked_bar.eps'), 
       bg = 'transparent', height = 8, width = 8.8)
```

```{r SI plots: maf vs. site depth}
# maf vs. site depth
p_maf_vs_depth = bind_rows(snps_vitoria,snps_bc, snps_walker) %>%
  mutate(study = case_when(study == 'Colangeli' ~ 'Colangeli et al. (2020)', 
                           study == 'Guthrie' ~ 'Guthrie et al. (2018)',
                           study == 'Walker' ~ 'Walker et al. (2014)', 
                          TRUE ~ NA)) %>%
  filter(!(dp_flag == 'Low depth' | ppe_flag == "PE/PPE")) %>%
  ggscatter(y = 'maf', x = 'DP', color = 'study',palette = 'jco', scales = 'free') +
  stat_cor(method = "pearson", label.y = .52, size = 3) +
  facet_wrap(~study, scales = 'free_x') +
  theme_classic() +
  ylab('Minor allele frequency') + xlab('Site depth of coverage')
p_maf_vs_depth

# Number of iSNVs per sample vs. median depth
p_isnv_vs_depth = shared_snps_filtered %>%
  filter(threshold == .01 & pair_id == 'Sample') %>%
  rowwise() %>%
  mutate(Sample = str_split(pair_name,'_', simplify = TRUE)[1]) %>%
  left_join(run_summary) %>%
  ggscatter(x = 'Coverage_Median', y = 'n', color = 'study',palette = 'jco', scales = 'free') +
  stat_cor(method = "pearson", size = 3) +
  facet_wrap(~study, scales = 'free') +
  theme_classic() +
  ylab('Number minority variants') + xlab('Coverage median')

plot_grid(p_isnv_vs_depth, p_maf_vs_depth, nrow = 2, labels = 'auto')
```

```{r SI plots: correlation of mafs}

vitoria_shared = read_csv(here('results/processed/vitoria_shared_snps_ann.csv')) %>%
  mutate(study = 'Colangeli')
bc_shared = read_csv(here('results/processed/bc_shared_snps_ann.csv')) %>%
  mutate(study = 'Guthrie')
walker_shared = read_csv(here('results/processed/walker_shared_snps_ann.csv')) %>%
  mutate(study = 'Walker')

# Read in shared SNPs to look at maf correlations
p_maf_corr = vitoria_shared  %>%
  bind_rows(bc_shared) %>%
  bind_rows(walker_shared) %>% 
    mutate(study = case_when(study == 'Colangeli' ~ 'Colangeli et al. (2020)', 
                           study == 'Guthrie' ~ 'Guthrie et al. (2018)',
                           study == 'Walker' ~ 'Walker et al. (2014)', 
                          TRUE ~ NA)) %>%
  filter(ppe_flag == "Outside" & dp_flag == "Expected" & pair_id == 'Household' & maf.x >= .01 & maf.y >= .01) %>% 
  ggscatter(x = 'maf.x', y = 'maf.y', facet.by = 'study',
  add = "reg.line", add.params = list(color = "gray", fill = "lightgray",
   conf.int = TRUE, cor.coef = TRUE)) + 
  stat_cor(method = "pearson", label.x = .14, label.y = .44, size = 3, cor.coef.name = 'r') +
  xlab('Minor allele frequency, isolate 1') + 
  ylab('Minor allele frequency, isolate 2')

ggsave(p_maf_corr, filename = here('plots/maf_corr.pdf'), height = 6, width = 8)

# Remove large files
rm(bc_shared,vitoria_shared,walker_shared)
```
```{r SI plot: variant effect }

snps_hh %>%
  separate_wider_delim(ANN, delim = '|', names = c('allele','effect','putative_impact','gene_name','gene_id','feature_type','feature_id',NA,NA,'HGVS.c','HGVS.p'), too_many = 'drop',too_few = 'align_start')  %>%   
  filter(ppe_flag == "Outside PE/PPE genes" & dp_flag == "Expected" & maf >= .01) %>%
  filter(effect %in% c('missense_variant','intergenic_region','synonymous_variant')) %>%
  group_by(POS, effect, study) %>% dplyr::summarize(n = n()) %>%
  ggplot(aes(x = n, fill = effect), show.legend = FALSE) + 
  geom_histogram() +    
  facet_grid(rows = vars(effect), cols = vars(study), scales = 'free_y') + theme_classic() + 
  scale_fill_jco() + theme(legend.position = "none") + 
  xlab('Number of samples with mutation')

# Which were most common sites across all three studies? 
snps_hh %>%
  separate_wider_delim(ANN, delim = '|', names = c('allele','effect','putative_impact','gene_name','gene_id','feature_type','feature_id',NA,NA,'HGVS.c','HGVS.p'), too_many = 'drop',too_few = 'align_start')  %>%   
  filter(ppe_flag == "Outside PE/PPE genes" & dp_flag == "Expected" & maf >= .01) %>%
  #filter(effect %in% c('missense_variant','intergenic_region','synonymous_variant')) %>%
  group_by(POS, effect) %>% 
  dplyr::summarize(n = n()) %>% arrange(-n)

snps_hh %>%
    filter(ppe_flag == "Outside PE/PPE genes" & dp_flag == "Expected" & maf >= .01 & POS == 580772)

# How many minority variants are stop gained or stop lost
"stop_gained"
snps_hh %>%
  separate_wider_delim(ANN, delim = '|', names = c('allele','effect','putative_impact','gene_name','gene_id','feature_type','feature_id',NA,NA,'HGVS.c','HGVS.p'), too_many = 'drop',too_few = 'align_start')  %>%   
  filter(ppe_flag == "Outside PE/PPE genes" & dp_flag == "Expected" & maf >= .01) %>%
  group_by(effect) %>% dplyr::summarize(n = n()) %>% arrange(-n) %>% 
  summarize(sum(n))
  
```
```{r SI plot: time between sample collection vs. shared variants}
# Colangeli et al. samples
shared_snps_summary %>% 
  filter( pair_id == 'Household' & ppe_flag == 'Outside' & dp_flag == 'Expected' & study == 'Colangelli') %>%
  dplyr::left_join(meta_vitoria, by = 'pair_name') %>% 
  ggplot(aes(x = months, y = n)) + geom_point() + theme_classic() + 
  stat_cor(p.accuracy = 0.001, r.accuracy = 0.01)+
  facet_wrap(~threshold, scales = 'free_y') + geom_smooth(method = "lm") + 
  xlab('Months between sampling of index & household contact') +
  ylab('Shared minority variants')

```

```{r capture}
# Read in capture metadata
meta_capture_full = read_csv(file = here('metadata/capture.csv'))

# Read in capture snps
capture_snps_table_file = here('results/processed/capture_snps.csv')
capture_snps = read_csv(capture_snps_table_file)

# Confirm all samples have corresponding metadata
#unique(capture_snps$Sample)[which(!unique(capture_snps$Sample) %in% meta_capture$experiment_accession)]

# Summarize iSNVs per sample & beeswarm by study and method
capture_filt <- capture_snps %>%
  filter(!(dp_flag == 'Low depth') & AD1 >= 5 & AD2 >= 5) %>%
  filter(ppe_flag == 'Outside') %>%
  left_join(meta_capture_full, by = c('Sample' = 'experiment_accession')) %>%
  filter(Coverage_Median >= 25) %>%
  group_by(Sample, ppe_flag, Approach, study, smear, Patient, Coverage_Median) %>%
  summarize(n_isnvs = n()) %>%
  mutate(smear = factor(smear, levels = c('negative','scanty','1+','2+','3+')),
    Approach = factor(Approach, levels = c('culture','lysis','BAL capture','culture capture','sputum capture')), 
    Patient = paste0(study,Patient))

# Plot by approach, compare to reference
capture_filt %>% 
  ggboxplot(x = 'Approach', y = 'n_isnvs', color = 'Approach', palette = 'jco', add = 'jitter') + 
  facet_wrap(~study, scales = 'free_x') + #scales = 'free_x'
  theme_classic() +
  scale_y_continuous(trans='log10') +
  theme(axis.text.x = element_text(angle = 45, vjust = .6)) + 
  ylab('Minority variants')

# Compare means against reference group (culture) - none significantly differed from culture
compare_means(data = capture_filt, n_isnvs ~ Approach, group.by = 'study', ref.group = 'culture', method = 'wilcox.test')

# Paired plots
capture_filt %>% ungroup() %>% 
  group_by(study, Patient) %>% filter(n() > 1) %>% #ungroup() %>%
  arrange(study, Approach, Patient) %>% 
  #filter(study == 'Goig') %>%
  ggpaired(x = 'Approach', y = 'n_isnvs', id = 'Patient', color = 'Approach', palette = 'jco',line.color = 'gray', line.size = 0.4, 
           facet.by = 'study',  scales = "free_x") + 
  theme_classic() +
  scale_y_continuous(trans='log10') +
  theme(axis.text.x = element_text(angle = 45, vjust = .6)) + 
  ylab('Number iSNVs') 
  
# Compare means against reference group (culture) - none significantly differed from culture
brown_df = capture_filt %>% filter(study == 'Brown') %>% ungroup() %>% group_by(study, Patient) %>% filter(n() > 1) %>%
  arrange(study, Approach, Patient) %>%
  mutate(comparison_group = paste0(sort(unique(Approach)), collapse = '_'))

compare_means(data = brown_df, n_isnvs ~ Approach, id = 'Patient', method = "wilcox.test", paired = TRUE, group.by = 'comparison_group')

doyle_df = capture_filt %>% filter(study == 'Doyle') %>% ungroup() %>% group_by(study, Patient) %>% filter(n() > 1) %>%
  arrange(study, Approach, Patient) %>%
  mutate(comparison_group = paste0(sort(unique(Approach)), collapse = '_'))
compare_means(data = doyle_df, n_isnvs ~ Approach, id = 'Patient', method = "wilcox.test", paired = TRUE, group.by = 'comparison_group')

goig_df = capture_filt %>% filter(study == 'Goig') %>% group_by(study, Patient) %>% filter(n() > 1) %>%
  arrange(study, Approach, Patient) %>%
  mutate(comparison_group = paste0(sort(unique(Approach)), collapse = '_'))
compare_means(data = goig_df, n_isnvs ~ Approach, id = 'Patient', method = "wilcox.test", paired = TRUE, group.by = 'comparison_group')

vot_df = capture_filt %>% filter(study == 'Votintseva') %>% group_by(study, Patient) %>% filter(n() > 1) %>%
  arrange(study, Approach, Patient) 
compare_means(data = vot_df, n_isnvs ~ Approach, id = 'Patient',method = "wilcox.test", paired = TRUE)

capture_filt %>% filter(!study == 'Votintseva') %>%
  ggboxplot(x = 'smear', y = 'n_isnvs', color = 'smear', palette = 'jco', add = 'jitter') + 
  facet_wrap(~study, scales = 'free_x') + #scales = 'free_x'
  theme_classic() +
  scale_y_continuous(trans='log10') +
  theme(axis.text.x = element_text(angle = 45, vjust = .6)) + 
  ylab('Minority variants')


```
```{r regression for minority variants}
# Poisson regression for # iSNVs

m1 = glm(n_isnvs ~ study + Approach + smear + Coverage_Median, data = capture_filt, family = poisson)
summary(m1)
cbind(exp(coefficients(m1)),exp(confint(m1)))

# Drop smear status as Votintseva does not report
m2 = glm(n_isnvs ~ study + Approach + Coverage_Median, data = capture_filt, family = poisson)
summary(m2)
cbind(exp(coefficients(m2)),exp(confint(m2)))

# Predict model 1 output
newdata1 <- expand.grid(Approach = unique(capture_filt$Approach), Coverage_Median = seq(0,500, by = 50)) %>%
  mutate(study = 'Brown', smear = '1+')
newdata1 <- cbind(newdata1, predict(m1, newdata = newdata1,type = "response", se = TRUE))

# Plot model predictions
ggplot(newdata1, aes(x = Coverage_Median, y = fit)) + 
  geom_ribbon(aes(ymin = fit - se.fit,
    ymax = fit + se.fit, fill = Approach), alpha = 0.2) + 
  geom_line(aes(colour = Approach),size = 1) + 
  xlab('Coverage') + ylab('Predicted minority variants') +
  theme_classic()

# Report increase from 50 to 100X coverage
newdata1 %>% 
  filter(Coverage_Median %in% c(50,100,200) & Approach == 'sputum capture')

# GOF
1-pchisq(m1$deviance, m1$df.residual)

# Random intercept, including pair (needs to also include)-no convergence, not reported.
m2 = glmer(n_isnvs ~ study + Approach + smear + Coverage_Median + (1 | Patient),  data = capture_filt, 
           family = poisson(link = "log"))
summary(m2)
cbind(exp(coefficients(m2)),exp(confint(m2)))

```
